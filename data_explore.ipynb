{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Mapping relationship of category_id and LabelName\n",
    "# from mmrotate.datasets import ShipDataset\n",
    "\n",
    "# id2category = {i: c\n",
    "#                    for i, c in enumerate(ShipDataset.METAINFO['classes'])\n",
    "#             }\n",
    "# json_path = '/remote-home/syfeng/MyProject/mmrotate/work_dirs/rtmdet_r/Task1.bbox.json'\n",
    "# csv_path = '/remote-home/syfeng/MyProject/mmrotate/work_dirs/rtmdet_r/box.csv'\n",
    "\n",
    "# # Load JSON data from file\n",
    "# with open(json_path, 'r') as json_file:\n",
    "#     json_data = json.load(json_file)\n",
    "\n",
    "# # Prepare CSV file for writing\n",
    "# with open(csv_path, 'w', newline='') as csv_file:\n",
    "#     writer = csv.writer(csv_file)\n",
    "    \n",
    "#     # Write CSV header\n",
    "#     writer.writerow([\"ImageID\", \"LabelName\", \"X1\", \"Y1\", \"X2\", \"Y2\", \"X3\", \"Y3\", \"X4\", \"Y4\", \"Conf\"])\n",
    "    \n",
    "#     # Process each JSON object and write to CSV\n",
    "#     for item in json_data:\n",
    "#         image_id = item[\"image_id\"] + \".bmp\"\n",
    "#         bbox = item[\"bbox\"]\n",
    "#         score = item[\"score\"]\n",
    "#         category_id = item[\"category_id\"]\n",
    "        \n",
    "#         # Map category_id to LabelName\n",
    "#         label_name = category_mapping.get(category_id, \"Unknown\")\n",
    "        \n",
    "#         # Write CSV row\n",
    "#         writer.writerow([image_id, label_name] + bbox + [score])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmrotate\n",
    "from mmrotate.datasets import ShipDataset\n",
    "from mmrotate.evaluation.metrics import ShipMetric\n",
    "from mmengine.evaluator import Evaluator\n",
    "from mmengine.fileio import load\n",
    "metrics = ShipMetric(format_only=True, outfile_prefix='./work_dirs_debug/')\n",
    "metrics.dataset_meta = ShipDataset.METAINFO\n",
    "# Build the evaluator. The parameter `metrics` is the configuration of the evaluation metric\n",
    "evaluator = Evaluator(\n",
    "    metrics=metrics,\n",
    ")\n",
    "data_samples = load('/remote-home/syfeng/MyProject/mmrotate/work_dirs_debug/epoch_36.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/29 17:32:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - results are saved in ./work_dirs_debug\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "results = evaluator.offline_evaluate(data_samples, chunk_size=128)\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to get image size\n",
    "def get_image_size(image_path):\n",
    "    with Image.open(image_path) as img:\n",
    "        return img.size\n",
    "\n",
    "# Define the paths to the train and test directories\n",
    "train_dir = \"data/ship/train/images/\"\n",
    "test_dir = \"data/ship/test/images/\"\n",
    "\n",
    "# Initialize empty dictionaries to store the image info\n",
    "image_info = {}\n",
    "non_standard_images = {}\n",
    "\n",
    "# Function to update the JSON files\n",
    "def update_json(image_info, non_standard_images):\n",
    "    with open(\"work_dirs/image_info.json\", \"w\") as json_file:\n",
    "        json.dump(image_info, json_file)\n",
    "    with open(\"work_dirs/non_standard_images.json\", \"w\") as json_file:\n",
    "        json.dump(non_standard_images, json_file)\n",
    "\n",
    "# Analyze images in the train directory\n",
    "train_images = os.listdir(train_dir)\n",
    "for image_file in tqdm(train_images):\n",
    "    image_path = os.path.join(train_dir, image_file)\n",
    "    image_size = get_image_size(image_path)\n",
    "    image_info[image_file] = image_size\n",
    "    if image_size != (1024, 1024):\n",
    "        non_standard_images[image_file] = image_size\n",
    "    update_json(image_info, non_standard_images)\n",
    "\n",
    "# Analyze images in the test directory\n",
    "# test_images = os.listdir(test_dir)\n",
    "# for image_file in test_images:\n",
    "#     image_path = os.path.join(test_dir, image_file)\n",
    "#     image_size = get_image_size(image_path)\n",
    "#     image_info[image_file] = image_size\n",
    "#     if image_size != (1024, 1024):\n",
    "#         non_standard_images[image_file] = image_size\n",
    "#     update_json(image_info, non_standard_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_dict = json.load(open(\"work_dirs/non_standard_images.json\"))\n",
    "len(size_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmrotate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
